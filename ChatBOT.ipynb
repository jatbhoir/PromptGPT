{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai \n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "# dotenv will reads the key-value pair from .env \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv) \n",
    "\n",
    "#openAI API_KEY\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Connection with openAI\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_response(prompt, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_response_from_generated_message(messages, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    response = client.chat.completions.create( \n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature, \n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "def older_chats(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_response_from_generated_message(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)\n",
    "\n",
    "context = [ {\n",
    "    'role':'system', \n",
    "    'content':'''\n",
    "        [Content]\n",
    "    '''\n",
    "} ]  # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value='Hi User, How may I help you? ', placeholder='Enter text hereâ€¦')\n",
    "button_conversation = pn.widgets.Button(name='Chat!')\n",
    "\n",
    "interactive_conversation = pn.bind(older_chats, button_conversation)\n",
    "\n",
    "#Generating Dashboard \n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages =  context.copy()\n",
    "# messages.append(\n",
    "# {''},    \n",
    "# )\n",
    " \n",
    "# response = get_response_from_generated_message(messages, temperature=0)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
